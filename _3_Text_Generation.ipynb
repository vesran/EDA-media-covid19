{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20minutes</td>\n",
       "      <td>CORONAVIRUS Après une alerte lancée il y a tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bfm</td>\n",
       "      <td>Parmi les trois foyers identifiés, l'un se tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnews</td>\n",
       "      <td>La France a enregistré 16 décès supplémentaire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lacroix</td>\n",
       "      <td>Ne pas baisser la garde. C’est en résumé le me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ledauphine</td>\n",
       "      <td>Un cas positif de Covid-19 a été détecté ce ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lefigaro</td>\n",
       "      <td>Sur un marché parisien, les commerçants prenne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lemonde</td>\n",
       "      <td>Le Brésil comptait, samedi 20 juin, près de 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lesechos</td>\n",
       "      <td>Par Les Echos\\n\\nPublié le 20 juin 2020 à 18h4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    newspaper                                               text\n",
       "0   20minutes  CORONAVIRUS Après une alerte lancée il y a tro...\n",
       "1         bfm  Parmi les trois foyers identifiés, l'un se tro...\n",
       "2       cnews  La France a enregistré 16 décès supplémentaire...\n",
       "3     lacroix  Ne pas baisser la garde. C’est en résumé le me...\n",
       "4  ledauphine  Un cas positif de Covid-19 a été détecté ce ve...\n",
       "5    lefigaro  Sur un marché parisien, les commerçants prenne...\n",
       "6     lemonde  Le Brésil comptait, samedi 20 juin, près de 1 ...\n",
       "7    lesechos  Par Les Echos\\n\\nPublié le 20 juin 2020 à 18h4..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press = pd.read_csv('./data/press.csv')[['newspaper', 'text']]\n",
    "press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coronavirus apres une alerte lancee il y a trois semaines sur un foyer de contaminations chez les saisonniers des bouchesdurhone , les nouveaux cas diminuent des travailleurs agricoles attendent pour se faire depister dans l ouest des bouchesdurhone . clement mahoudeau afp un foyer de contamination au coronavirus chez les travailleurs saisonniers de l ouest des bouchesdurhone a ete detecte au debut du mois de juin . les services de l etat ont eu du mal pour placer en quarantaine ces travailleurs saisonniers a cause de leurs conditions d hebergements souvent compliquees . sur <NB> travailleurs testes positifs , <NB> sont sortis de leur quarantaine . la bataille n est pas encore gagnee . le prefet des bouchesdurhone , pierre dartout , et le directeur de l agence regionale de sante de provence alpes cote d azur , philippe de mester , ont fait le point sur le foyer de contaminations au coronavirus chez des travailleurs saisonniers de l ouest du departement des bouchesdurhone . les nouvelle'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_string2(text):\n",
    "    clean_text = text.lower()\n",
    "    clean_text = re.sub('covid-19', 'coronavirus', clean_text)\n",
    "    clean_text = re.sub('[#:/\\%€@»«➡️—-]', '', clean_text)\n",
    "    clean_text = re.sub('’', ' \\' ', clean_text)\n",
    "    clean_text = re.sub('[éèëê]', 'e', clean_text)\n",
    "    clean_text = re.sub('[àâ]', 'a', clean_text)\n",
    "    clean_text = re.sub('[ïî]', 'i', clean_text)\n",
    "    clean_text = re.sub('[öô]', 'o', clean_text)\n",
    "    clean_text = re.sub(\"['\\n\\t]\", ' ', clean_text)\n",
    "    \n",
    "    clean_text = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", clean_text)\n",
    "    clean_text = re.sub('\\w*\\d\\w*', '<NB>', clean_text)  # Remove numbers\n",
    "    return ' '.join(clean_text.split())\n",
    "\n",
    "\n",
    "press['prepared_text'] = press.apply(lambda r: clean_string2(r['text']), axis=1)\n",
    "press.iloc[0]['prepared_text'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'la france a enregistre <NB> deces supplementaires lies au coronavirus dans les dernieres <NB> heures , portant le total des morts a <NB> . <NB> depuis le debut de l epidemie , selon le bilan publie samedi par sante publique france . selon l agence nationale de sante publique , le nombre de patients du coronavirus en reanimation continue parallelement de baisser avec <NB> malades , soit <NB> de moins que dans le bilan publie la veille par la direction generale de la sante ( dgs ) . au total , <NB> . <NB> personnes sont mortes dans les hopitaux , selon sante publique france . les donnees des deces en etablissements sociaux et medicosociaux , dont les ehpad , seront quant a elles actualisees mardi . le nombre total des personnes hospitalisees continue aussi de baisser , avec desormais <NB> . <NB> patients dans tout le pays . deux departements continuent d etre en situation de vulnerabilite elevee la guyane et mayotte . dans tout le territoire , le nombre de foyers epidemiques ( clusters )'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus on one newspaper\n",
    "newspaper = 'cnews'\n",
    "assert newspaper in press.newspaper.values\n",
    "\n",
    "based_text = press.set_index('newspaper').loc[newspaper, 'prepared_text']\n",
    "print(len(based_text.split(' ')))\n",
    "based_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary\n",
    "vocab = sorted(set(based_text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappers\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Dataset of sequences with a specific size\n",
    "\n",
    "chunk_size = 11\n",
    "chunks = []\n",
    "whole_sequence = based_text.split(' ')\n",
    "for i in range(len(whole_sequence) - chunk_size):\n",
    "    chunk = [word2idx[whole_sequence[i+t]] for t in range(chunk_size) if i+t < len(whole_sequence)]\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define targets\n",
    "y = []\n",
    "for chunk in chunks:\n",
    "    target = chunk.pop(-1)\n",
    "    y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(chunks)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(len(vocab)+1, 50))\n",
    "    model.add(tf.keras.layers.LSTM(64))\n",
    "    model.add(tf.keras.layers.Dense(len(vocab)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 2s 11ms/step - loss: 2.0195\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.9734\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.9200\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.8760\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.8316\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.7949\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.7499\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.7007\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.6620\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 1.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dafbbbbaf0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mais le gouvernement a mis en place un plan de relance. Un assouplissement al por los medicos fois que le tabou d autres etudes du resultats de confinement, selon le gouvernement a <NB>. <NB>. <NB> cas ), l oms depuis le coronavirus ici les dernieres <NB> heures, selon l ensemble du professeur xinhuan de l autorite du travail et la sante, d immunite en revanche a la sante ( dgs ), le debut de l epidemie. Le coronavirus ici les salles de tels vague epidemique, dont une phase europeens, dont les ehpad, selon l etude du professeur cruz. Les salles de television bolivienne d une part. Le virus, on peut voir d une majorite de television inexorablement. Inquietudes de l epidemie. Le coronavirus ici les salles de tels vague epidemique, dont une phase europeens, dont les ehpad, selon l etude du professeur cruz. Les salles de television bolivienne d une part. Le virus, on peut voir d une majorite de television inexorablement. Inquietudes de l epidemie. Le coronavirus ici les salles de tels vague epidemique, dont une phase europeens, dont les ehpad, '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate_tokens = 200\n",
    "    \n",
    "    # Encode start string\n",
    "    clean_start = clean_string2(start_string)\n",
    "    start_sequence = np.array([word2idx[word] for word in clean_start.split(' ')]).reshape(1, chunk_size-1)\n",
    "    \n",
    "    text_generated = clean_start.split(' ')\n",
    "    model.reset_states()\n",
    "    current_sequence = start_sequence\n",
    "    for i in range(num_generate_tokens):\n",
    "        predictions = model(current_sequence)\n",
    "        \n",
    "        p = 1\n",
    "        next_idx = rand.choice(np.argsort(predictions[0])[-p:][::-1])\n",
    "        next_word = idx2word[next_idx]\n",
    "        text_generated.append(next_word)\n",
    "        \n",
    "        # Copy n-1 last words\n",
    "        current_sequence = np.concatenate([current_sequence[0][1:], [next_idx]], axis=0).reshape(1, chunk_size-1)\n",
    "        \n",
    "    # Clean generated text\n",
    "    final_text = ''\n",
    "    for i in range(len(text_generated)):\n",
    "        \n",
    "        if i == 0 or (text_generated[i-1] == '.' and text_generated[i] not in string.punctuation and text_generated[i] != '<NB>'):\n",
    "            clean = text_generated[i][0].upper() + text_generated[i][1:]\n",
    "            clean += ' '\n",
    "        elif i < len(text_generated)-1 and text_generated[i+1] in ('.', ',', '\\''):\n",
    "            clean = text_generated[i]\n",
    "        else:\n",
    "            clean = text_generated[i]\n",
    "            clean += ' '\n",
    "        final_text += clean\n",
    "        \n",
    "    return final_text\n",
    "\n",
    "\n",
    "start_string = 'Mais le gouvernement a mis en place un plan de'\n",
    "generate_text(model, start_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
